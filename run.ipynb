{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/sourav/miniconda3/envs/pt2\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=11.0\n",
      "    - pytorch==1.7.1\n",
      "    - torchaudio==0.7.2\n",
      "    - torchvision==0.8.2\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2023.7.22~ --> pkgs/main/linux-64::certifi-2023.7.22-py38h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes -n pt2 pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.14.3 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.14.3)\n",
      "Requirement already satisfied: numpy==1.19.2 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.19.2)\n",
      "Requirement already satisfied: tqdm==4.62.3 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (4.62.3)\n",
      "Requirement already satisfied: transformers==4.11.3 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (4.11.3)\n",
      "Requirement already satisfied: seqeval==1.2.2 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.2.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from datasets==2.14.3->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: filelock in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from transformers==4.11.3->-r requirements.txt (line 4)) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from transformers==4.11.3->-r requirements.txt (line 4)) (2022.7.9)\n",
      "Requirement already satisfied: sacremoses in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from transformers==4.11.3->-r requirements.txt (line 4)) (0.0.53)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from transformers==4.11.3->-r requirements.txt (line 4)) (0.10.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from seqeval==1.2.2->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 1)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from aiohttp->datasets==2.14.3->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.3->-r requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.14.3->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.14.3->-r requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.14.3->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 5)) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from pandas->datasets==2.14.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from pandas->datasets==2.14.3->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: six in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from sacremoses->transformers==4.11.3->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: click in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from sacremoses->transformers==4.11.3->-r requirements.txt (line 4)) (8.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (1.7.1)\n",
      "Requirement already satisfied: typing_extensions in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: numpy in /home/sourav/miniconda3/envs/pt2/lib/python3.8/site-packages (from torch) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "08/11/2023 12:35:30 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "08/11/2023 12:35:30 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=checkpoints/rte-roberta/runs/Aug11_12-35-30_uno,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=100.0,\n",
      "output_dir=checkpoints/rte-roberta/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=checkpoints/rte-roberta/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.NO,\n",
      "save_total_limit=None,\n",
      "seed=11,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "[INFO|tokenization_auto.py:334] 2023-08-11 12:35:30,960 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:583] 2023-08-11 12:35:31,372 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/sourav/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "[INFO|configuration_utils.py:620] 2023-08-11 12:35:31,374 >> Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1741] 2023-08-11 12:35:34,546 >> loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/sourav/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|tokenization_utils_base.py:1741] 2023-08-11 12:35:34,547 >> loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/sourav/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1741] 2023-08-11 12:35:34,547 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /home/sourav/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "[INFO|tokenization_utils_base.py:1741] 2023-08-11 12:35:34,547 >> loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2023-08-11 12:35:34,547 >> loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1741] 2023-08-11 12:35:34,547 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:583] 2023-08-11 12:35:35,059 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/sourav/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "[INFO|configuration_utils.py:620] 2023-08-11 12:35:35,060 >> Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Loading Dataset Infos from /home/sourav/.cache/huggingface/modules/datasets_modules/datasets/super_glue/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed\n",
      "08/11/2023 12:35:38 - INFO - datasets.info - Loading Dataset Infos from /home/sourav/.cache/huggingface/modules/datasets_modules/datasets/super_glue/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "08/11/2023 12:35:38 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed\n",
      "08/11/2023 12:35:38 - INFO - datasets.info - Loading Dataset info from /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed\n",
      "Found cached dataset super_glue (/home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
      "08/11/2023 12:35:38 - INFO - datasets.builder - Found cached dataset super_glue (/home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n",
      "Loading Dataset info from /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed\n",
      "08/11/2023 12:35:38 - INFO - datasets.info - Loading Dataset info from /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed\n",
      "{'entailment': 0, 'not_entailment': 1}\n",
      "{0: 'entailment', 1: 'not_entailment'}\n",
      "Loading cached processed dataset at /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-c9e05d8291c1fd3d.arrow\n",
      "08/11/2023 12:35:38 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-c9e05d8291c1fd3d.arrow\n",
      "Loading cached processed dataset at /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-d03f14f62fcf6ca7.arrow\n",
      "08/11/2023 12:35:38 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-d03f14f62fcf6ca7.arrow\n",
      "Loading cached processed dataset at /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-d1d6a9f37ade5531.arrow\n",
      "08/11/2023 12:35:38 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/sourav/.cache/huggingface/datasets/super_glue/rte/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/cache-d1d6a9f37ade5531.arrow\n",
      "/home/sourav/research/P-tuning-v2/tasks/superglue/dataset.py:98: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  self.metric = load_metric(\"super_glue\", data_args.dataset_name)\n",
      "08/11/2023 12:35:40 - INFO - tasks.superglue.get_trainer - Sample 1852 of the training set: {'premise': 'In 1975, a 19 year old Wilkins was handed the captaincy of Chelsea, despite the presence of elder and more experienced players in the squad.', 'hypothesis': 'Wilkins became the captain of Chelsea in 1975.', 'idx': 1852, 'label': 0, 'input_ids': [0, 1121, 14873, 6, 10, 753, 76, 793, 3884, 7327, 21, 4507, 5, 3449, 4469, 9, 3098, 6, 1135, 5, 2621, 9, 15172, 8, 55, 2984, 472, 11, 5, 2837, 4, 2, 2, 28886, 7327, 1059, 5, 3449, 9, 3098, 11, 14873, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "08/11/2023 12:35:40 - INFO - tasks.superglue.get_trainer - Sample 2292 of the training set: {'premise': 'Hubble is helping astronomers precisely calculate the age of the universe by providing accurate distances to galaxies, an important prerequisite for calculating age. Hubble measures the distances to neighboring galaxies by finding accurate \"milepost markers,\" a special class of pulsating star called Cepheid variables. These, in turn, are being used to calibrate more remote milepost markers.', 'hypothesis': 'Hubble discovers black holes.', 'idx': 2292, 'label': 1, 'input_ids': [0, 23730, 5225, 16, 1903, 30339, 12810, 15756, 5, 1046, 9, 5, 9468, 30, 1976, 6030, 21459, 7, 30948, 6, 41, 505, 39364, 13, 29770, 1046, 4, 37006, 1797, 5, 21459, 7, 10935, 30948, 30, 2609, 6030, 22, 7800, 7049, 22462, 60, 10, 780, 1380, 9, 33463, 1295, 999, 373, 230, 2462, 30071, 25083, 4, 1216, 6, 11, 1004, 6, 32, 145, 341, 7, 43460, 877, 55, 6063, 7245, 7049, 22462, 4, 2, 2, 23730, 5225, 28411, 909, 6538, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "08/11/2023 12:35:40 - INFO - tasks.superglue.get_trainer - Sample 1907 of the training set: {'premise': 'That theory, a concept first proposed by Albert Einstein and often reiterated by British astrophysicist Stephen Hawking, seeks to find a single set of equations that can explain all the fundamental forces in the universe: gravity, electromagnetism, and the strong and weak interactive forces among subnuclear particles.', 'hypothesis': 'Stephen Hawking is a physicist.', 'idx': 1907, 'label': 0, 'input_ids': [0, 1711, 6680, 6, 10, 4286, 78, 1850, 30, 8098, 27648, 8, 747, 8277, 30, 1089, 38685, 2459, 39302, 3259, 27604, 6, 6330, 7, 465, 10, 881, 278, 9, 43123, 14, 64, 3922, 70, 5, 6451, 1572, 11, 5, 9468, 35, 17244, 6, 45475, 1073, 4135, 1809, 6, 8, 5, 670, 8, 3953, 10813, 1572, 566, 2849, 31242, 16710, 4, 2, 2, 30273, 27604, 16, 10, 33832, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "[INFO|configuration_utils.py:583] 2023-08-11 12:35:40,989 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/sourav/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "[INFO|configuration_utils.py:620] 2023-08-11 12:35:40,990 >> Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"rte\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1323] 2023-08-11 12:35:41,511 >> loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/sourav/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n",
      "total param is 6293506\n",
      "[WARNING|modeling_utils.py:1579] 2023-08-11 12:35:43,071 >> Some weights of the model checkpoint at roberta-large were not used when initializing RobertaPrefixForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaPrefixForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaPrefixForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:1590] 2023-08-11 12:35:43,071 >> Some weights of RobertaPrefixForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight', 'prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!bash run_script/run_rte_roberta.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
